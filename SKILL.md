---
name: code-review-report
description: |
  前端代码 Code Review 分析报告和人工/AI Coding 开发效率评估。

  触发场景：
  - 用户请求代码评估、Code Review、代码质量报告
  - 用户请求两周/一周/本周的代码分析
  - 用户请求开发效率评估、AI coding 评估、工时对比
  - 用户用口语表达如"帮我看看代码"、"分析下代码"、"代码写得怎么样"

  输出内容：代码质量评分、AI代码占比分析、功能模块工时对比表、改进建议
---

# 前端代码评估报告技能

## 执行流程

```
获取时间范围 → 收集Git数据 → 统计AI代码标记 → 代码质量分析 → 生成报告
```

## 核心步骤

### 1. 收集数据

运行 Git 分析脚本获取统计数据：

```bash
scripts/analyze-git.sh "2 weeks ago" "now"
```

脚本输出：提交次数、AI标记提交、代码变更行数、涉及文件数

### 2. 统计 AI 代码

扫描代码中的 AI 生成标记：

```javascript
// @ai-generated-start
// @ai-generated-end
```

统计带 `[AI]` 标记的 Git 提交

### 3. 生成报告

使用模板 `assets/report-template.md` 生成报告，包含：

| 模块           | 内容                                            |
| -------------- | ----------------------------------------------- |
| 代码质量总览   | 评分(/100)、TS覆盖率、提交/变更统计、AI代码占比 |
| AI专项分析     | AI代码分布、质量等级、门禁检查                  |
| 深度检查       | 类型系统、组件设计、性能、样式、安全            |
| 功能模块评估表 | 人工 vs AI Coding 工时对比、效率提升比          |
| 改进建议       | P0/P1/P2 优先级问题、改进路线图                 |

## 资源文件

| 文件                        | 用途                        |
| --------------------------- | --------------------------- |
| `scripts/analyze-git.sh`    | Git 数据统计脚本            |
| `assets/report-template.md` | 报告输出模板                |
| `REFERENCE.md`              | 检查清单、KPI定义、评分标准 |
| `EXAMPLES.md`               | 完整报告示例                |
| `references/*.md`           | 项目原始文档（4个）         |

## 使用示例

```
请生成两周内的代码评估报告
生成 2026-01-20 至 2026-02-03 的 code review 报告
分析 src/pages 目录的代码质量
```
